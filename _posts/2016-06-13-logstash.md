---
layout: wordpress
title: Extração de dados com Logstash
excerpt: |
  Veja como trabalhar com o Logstash, uma ferramenta de extração de dados com foco na performance
date: 2016-06-13 12:00:05
author: jaswdr
permalink: /logstash/
image: /assets/wp-content/uploads/2016/05/logstash-logo.png
categories:
  - Desenvolvimento
  - Ferramentas
tags:
  - elk
  - extração de dados
  - logstash
---

Logstash basicamente é uma ferramenta de extração de dados, seu uso é simples, você determina um entrada (input), extrai informações que atendem a um padrão com filtros (filters) e gera uma saída (output), o famoso "entrada -&gt; processo -&gt; saída". Seguindo esse conceito base, para cada etapa, o logstash possuí vários "plugins" que são pequenos programas que fazem as integrações do logstash, cada etapa possuí seus plugins, o que faz com que você possa fazer a entrada, processo e saída de várias formas diferentes.
<!--more-->
Para entender melhor esse conceito irei exemplificar a seguir, porém, antes de mais nada vamos fazer a instalação do logstash.

Instalação A processo de instalação é bem simples, você pode fazer o download no site oficial ou executar os comandos abaixo mudando os parâmetros conforme sua necessidade.

<pre><code class="bash">
wget https://download.elastic.co/logstash/logstash/logstash-2.3.2.tar.gz
tar -xvf logstash-2.3.2.tar.gz
sudo ln -s /caminho_para_pasta_logstash-2.3.2/bin/logstash /usr/local/bin/logstash
</code></pre>

Caso nenhum erro ocorra você terá agora acesso ao comando "logstash", teste executando "logstash --help", veremos agora um primeiro exemplo.
<h2>Exemplo 1: Lendo e escrevendo no terminal</h2>
O primeiro exemplo que irei demonstrar será o de ler e escrever no próprio terminal.
Toda vez que você utilizar o logstash será preciso passar como parâmetro um arquivo de configuração, tipicamente com extensão ".cnf", que determinará o que o logstash deve fazer, segue abaixo a configuração do exemplo citado.

<pre><code class="bash">
input { stdin { } } output { stdout {} }
</code></pre>

Salve o texto acima em um arquivo nome qualquer como "pipeline.conf" e rode o seguinte comando.

<pre><code class="bash">
logstash -f pipeline.conf
</code></pre>

Você vai perceber que o programa não termina de executar, digite algo no terminal e aperte enter, algo como a imagem abaixo será exibido.

<figure class="graf--figure">
<div class="aspectRatioPlaceholder is-locked">

[caption id="" align="aligncenter" width="500"]<img class="graf-image" src="https://cdn-images-1.medium.com/max/800/1*_8dVDgOGrJDPz3Uh5eAEXg.gif" width="500" height="150" data-image-id="1*_8dVDgOGrJDPz3Uh5eAEXg.gif" data-width="500" data-height="150" /> Exemplo 1: Lendo e escrevendo no terminal[/caption]

</div>
<figcaption class="imageCaption"></figcaption></figure>Simples não acha ? qualquer texto digitado no terminal será impresso no formato do logstash, vamos agora a um exemplo mais complexo onde iremos adicionar filtros para extrair dados de um arquivo.
<h2>Exemplo 2: Lendo um arquivo e extraindo dados</h2>
No segundo exemplo que veremos iremos ler de um arquivo de texto e imprimir na saída o resultado que obtivemos.

Assim como no exemplo anterior precisaremos criar um arquivo de configuração, vamos dar o nome de “extractPipeline.conf”, abaixo segue o conteúdo inicial deste arquivo adaptado do exemplo anterior.

<pre><code class="bash">
input {
    file {
        path =&gt; “/caminho/absoluto/para/arquivo.log”
        start_position =&gt; beginning
        ignore_older =&gt; 0
    }
}

output {
    stdout {}
}
</code></pre>

Observe que adicionamos o plugin “file”, como o próprio nome diz, este é um plugin para fazer leituras de arquivos, dentro desta tag podemos passar alguns parâmetros, o principal é “path” que é o caminho absoluto para o arquivo que queremos ler, o segundo é “start_position” que indica ao logstash por onde deve começar a leitura, por padrão ele apenas monitora novas entradas no arquivo, algo semelhante ao comando “tail -f” do Linux, por último temos o parâmetro “ignore_older” isto é necessário pois por padrão o plugin considera arquivo com a data de modificação até 86400 segundos anteriores a data e hora atual. Para este exemplo criei um arquivo com o seguinte conteúdo.

<pre><code class="bash">
linha 1
linha 2
linha 3
</code></pre>

Rodando o comando “logstash -f extractPipeline.conf” teremos a seguinte saída.

Caso precise rodar mais vezes será necessário abrir e salvar o arquivo de entrada, nesse caso “arquivo.log” para que o logstash detecte a mudança na data de modificação do arquivo e execute novamente, como utilizamos a tag “start_position” como “beginning” ele sempre fará a leitura a partir do começo do arquivo, do contrário apenas irá considerar as novas linhas.

<figure class="graf--figure">
<div class="aspectRatioPlaceholder is-locked">

[caption id="" align="aligncenter" width="424"]<img class="graf-image" src="https://cdn-images-1.medium.com/max/800/1*Mf62bxoew3mDXYHr5FWU1g.gif" width="424" height="212" data-image-id="1*Mf62bxoew3mDXYHr5FWU1g.gif" data-width="424" data-height="212" /> Exemplo 2: Lendo um arquivo e extraindo dados[/caption]

</div>
</figure>No caso de arquivos cada linha representa um registro, para registros que usam mais de uma linha é necessário o uso de plugins como o multiline.

A próxima etapa será extrair alguma informação mais útil deste arquivo, vamos então começar a trabalhar com filtros, um filtro bastante comumente usado é o “grok”, este utiliza de regex para extrair informações de textos.

Para entender melhor como o grok funciona vamos a alguns exemplos de sua sintaxe, considere o seguinte texto em um arquivo.

<pre><code class="bash">
[2016-05-16 16:50:00] ERROR: Call to undefined function &quot;helloWorld()&quot;
</code></pre>

Para poder extrair corretamente as informações precisamos determinar qual o padrão da mensagem, nesse caso podemos dizer que o padrão é algo como.

<pre><code class="bash">
[ano-mes-dia hora:minutos:segundos] level: mensagem
</code></pre>

A partir desse processo de identificação do padrão podemos “traduzir” esse padrão para a sintaxe do grok.

<pre><code class="bash">
[[]%{YEAR:ano}[-]%{MONTHNUM:mes}[-]%{MONTHDAY:dia}[s]%{HOUR:horas}[:]%{MINUTE:minutos}[:]%{SECOND:segundos}[]][s]%{LOGLEVEL:nivel}[:][s]%{GREEDYDATA:mensagem}
</code></pre>

Não se assuste, vamos por partes, primeiramente acesse o site grokdebug, nele poderemos testar nosso script antes e enviar ao logstash, insira as informações conforme a imagem.

<figure class="graf--figure">
<div class="aspectRatioPlaceholder is-locked">

[caption id="" align="aligncenter" width="800"]<img class="graf-image" src="https://cdn-images-1.medium.com/max/800/1*P5hXc8dUMQNov6tz35ch0Q.gif" width="800" height="306" data-image-id="1*P5hXc8dUMQNov6tz35ch0Q.gif" data-width="960" data-height="368" data-action="zoom" data-action-value="1*P5hXc8dUMQNov6tz35ch0Q.gif" /> Exemplo 2: Lendo um arquivo e extraindo dados[/caption]

</div>
</figure>O resultado é mostrado logo abaixo.

<pre><code class="bash">
{
&quot;ano&quot;: [
[
&quot;2016&quot;
]
],
&quot;mes&quot;: [
[
&quot;05&quot;
]
],
&quot;dia&quot;: [
[
&quot;16&quot;
]
...
</code></pre>

Esta é a saída do processamento da entrada pelo filtro, podemos redirecionar para um outro filtro ou para uma saída, definida pela tag “output”, mas antes vamos adicionar o filtro a nossa configuração, segue o conteúdo do arquivo.

<pre><code class="bash">
input {
file {
path =&gt; &quot;/caminho/absoluto/para/input.log&quot;
start_position =&gt; beginning
ignore_older =&gt; 0
}
}

filter {
grok {
match =&amp;gt; { &quot;message&quot; =&amp;amp;amp;gt; &quot;[[]%{YEAR:ano}[-]%{MONTHNUM:mes}[-]%{MONTHDAY:dia}[s]%{HOUR:horas}[:]%{MINUTE:minutos}[:]%{SECOND:segundos}[]][s]%{LOGLEVEL:nivel}[:][s]%{GREEDYDATA:mensagem}&quot; }
}
}

output {
stdout {}
}
</code></pre>

E claro, este é o conteúdo do arquivo de entrada que utilizaremos para esse exemplo.

<pre><code class="bash">
[2016-05-16 16:50:00] ERROR: Call to undefined function &quot;helloWorld()&quot;
[2016-05-16 16:55:00] ERROR: Call to undefined function &quot;helloWorld()&quot;
[2016-05-16 17:00:00] ERROR: Call to undefined function &quot;helloWorld()&quot;
</code></pre>

Executando temos o seguinte resultado.

<figure class="graf--figure">
<div class="aspectRatioPlaceholder is-locked">

[caption id="" align="aligncenter" width="800"]<img class="graf-image" src="https://cdn-images-1.medium.com/max/800/1*ll1UdajeVvfMJDht3gBE-Q.gif" width="800" height="124" data-image-id="1*ll1UdajeVvfMJDht3gBE-Q.gif" data-width="960" data-height="149" data-action="zoom" data-action-value="1*ll1UdajeVvfMJDht3gBE-Q.gif" /> Exemplo 2: Lendo um arquivo e extraindo dados[/caption]

</div>
</figure>Por fim vamos rodar esse mesmo comando porém adicionando um plugin de saída, usaremos aqui o plugin “csv” que gera arquivos “.csv” ou “comma-separated values”, altere a tag output para o seguinte.

<pre><code class="bash">
output {
stdout {}
csv{
fields =&gt; [“ano”,”mes”,”dia”,”horas”,”minutos”,”segundos”,”nivel”,”mensagem”]
path =&gt; “/caminho/absoluto/para/output.csv”
}
}
</code></pre>

Rode novamente o comando e o seguinte conteúdo deve aparecer no arquivo “output.csv”

<pre><code class="bash">
2016,05,16,16,50,00,ERROR,”Call to undefined function “”helloWorld()”””
2016,05,16,16,55,00,ERROR,”Call to undefined function “”helloWorld()”””
2016,05,16,17,00,00,ERROR,”Call to undefined function “”helloWorld()”””
</code></pre>

Perceba que cada valor está dividido por uma vírgula, a sequencia dos valores é determinada pela sequencia da tag “fields” passada na configuração.
<h2>Conclusão</h2>
Podemos concluir que o logstash é uma ótima alternativa para o processamento e extração de dados, a ferramenta é gratuita e pode ser integrada com outras como o Elasticsearch e Kibana, ambos da mesma empresa que criou o logstash.

Você conhecia o logstash ? Utiliza em alguma aplicação? Diga nos comentários :)